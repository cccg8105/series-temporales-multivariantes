---
title: "Mercados europeos"
author: "César Cárdenas"
date: "4/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_condaenv("env_rstudio")
```

## Descripción

## Librerias

```{python}
import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = 'C:/Users/cesar.cardenas/anaconda3/envs/env_rstudio/Library/plugins/platforms'

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import statsmodels.tsa.stattools as sts
from statsmodels.tsa.api import VAR
from statsmodels.tsa.stattools import grangercausalitytests
import statsmodels.graphics.tsaplots as sgt

import warnings
warnings.simplefilter('ignore')
```

## Importación de datos

```{python}
EuStocks = pd.read_csv('https://raw.githubusercontent.com/cccg8105/series-temporales-multivariantes/master/3.%20Casos%20de%20estudio%20en%20Python/B.%20Indices%20del%20mercado%20financiero%20europeo/EuIndices.csv')


# Arreglando el índice de la serie 
df_comp = pd.DataFrame(data = EuStocks.values, 
                           columns = ['0', 'DAX', 'SMI', 'CAC', 'FTSE'], 
                           index = pd.DatetimeIndex(pd.date_range(start="1991-01-01",periods = 1860, freq = 'B')))
df_comp = df_comp.drop(columns = ['0'])
df_comp.head(10)

```
```{python}
df_comp.isnull().sum()
```
 
## Analisis exploratorio

```{python}
fig, axes = plt.subplots(nrows=2, ncols=2, dpi=120, figsize=(8,6))
for i, ax in enumerate(axes.flatten()):
 data = df_comp[df_comp.columns[i]]
 ax.plot(data, color='red', linewidth=1)
 ax.set_title(df_comp.columns[i])
 ax.xaxis.set_ticks_position('none')
 ax.yaxis.set_ticks_position('none')
 ax.spines['top'].set_alpha(0)
 ax.tick_params(labelsize=6)
 plt.tight_layout();

plt.show()
```

### Correlación de variables

```{python}
corr=df_comp.corr()
corr

sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values, annot=True,vmax=1, vmin=-1, cmap =sns.diverging_palette(220, 10, as_cmap=True),center=0 )
plt.show()
```

Se visualiza que las variables estan altamente correlacionadas de forma directa

## Division de datos en entrenamiento y prueba

```{python}
n_obs=9
X_train, X_test = df_comp[0:-n_obs], df_comp[-n_obs:]
print(X_train.shape, X_test.shape)
```

## Prueba de estacionariedad

```{python}
def augmented_dickey_fuller_statistics(time_series):
  result = sts.adfuller(time_series.values)
  print('p-value: %f' % result[1])

print('Test de Dickey-Fuller Aumentado:')
print('Serie de tiempo DAX')
augmented_dickey_fuller_statistics(X_train['DAX'])
print('Serie de tiempo SMI')
augmented_dickey_fuller_statistics(X_train['SMI'])
print('Serie de tiempo CAC')
augmented_dickey_fuller_statistics(X_train['CAC'])
print('Serie de tiempo FTSE')
augmented_dickey_fuller_statistics(X_train['FTSE'])
```

### Transformación de datos

```{python}
X_train_transformed=X_train.diff().dropna()
X_train_transformed.head()
```

Visualización de la transformación

```{python}
# Dibujemos los datos transformados
fig, axes = plt.subplots(nrows=2, ncols=2, dpi=120, figsize=(8,6))
for i, ax in enumerate(axes.flatten()):
  d = X_train_transformed[X_train_transformed.columns[i]]
  ax.plot(d, color='red', linewidth=1)
  ax.set_title(df_comp.columns[i])
  ax.xaxis.set_ticks_position('none')
  ax.yaxis.set_ticks_position('none')
  ax.spines['top'].set_alpha(0)
  ax.tick_params(labelsize=6)
  plt.tight_layout();
  
plt.show()
```

### Nueva prueba de estacionariedad

```{python}
print('Test de Dickey-Fuller Aumentado:')
print('Serie de tiempo DAX Diferenciada')
augmented_dickey_fuller_statistics(X_train_transformed['DAX'])
print('Serie de tiempo SMI Diferenciada')
augmented_dickey_fuller_statistics(X_train_transformed['SMI'])
print('Serie de tiempo CAC Diferenciada')
augmented_dickey_fuller_statistics(X_train_transformed['CAC'])
print('Serie de tiempo FTSE Diferenciada')
augmented_dickey_fuller_statistics(X_train_transformed['FTSE'])
```

## Modelo VAR

```{python}
model = VAR(X_train_transformed)

modelsel=model.select_order(15)
print(modelsel.summary())

```
Según el analisis del AIC el modelo recomienda el orden 9.

Ajustando el modelo

```{python}
res = model.fit(maxlags=15, ic='aic')
print(res.summary())
```

## Causalidad de Granger

### DAX

```{python}
grangercaus=res.test_causality(['SMI', 'CAC', 'FTSE'],['DAX'],kind='f')
print(grangercaus.summary())
```
Se rechaza la hipotesis nula de que la variable no es causal de las demas. Por lo tanto si es causal debido a que el P valor es menor a 0.05

### SMI

```{python}
grangercaus=res.test_causality(['DAX', 'CAC', 'FTSE'],['SMI'],kind='f')
print(grangercaus.summary())
```

### CAC

```{python}
grangercaus=res.test_causality(['SMI', 'DAX', 'FTSE'],['CAC'],kind='f')
print(grangercaus.summary())
```

### FTSE

```{python}
grangercaus=res.test_causality(['SMI', 'CAC', 'DAX'],['FTSE'],kind='f')
print(grangercaus.summary())
```

Matriz de causalidad uno a uno

```{python}
maxlag=15
test = 'ssr_chi2test'
def grangers_causality_matrix(X_train_transformed, variables, test = 'ssr_chi2test', verbose=False):
  dataset = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)
  for c in dataset.columns:
    for r in dataset.index:
      test_result = grangercausalitytests(X_train_transformed[[r,c]], maxlag=maxlag, verbose=False)
      p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]
      if verbose: 
        print(f'Y = {r}, X = {c}, P Values = {p_values}')
      min_p_value = np.min(p_values)
      dataset.loc[r,c] = min_p_value
  dataset.columns = [var + '_x' for var in variables]
  dataset.index = [var + '_y' for var in variables]
  return dataset
grangers_causality_matrix(X_train_transformed, variables = X_train_transformed.columns)
```

### Diagnosis del modelo

```{python}
residuals=res.resid

fig, axs = plt.subplots(4)
fig.suptitle('Gráficos de los residuos',fontsize=20)
fig.set_size_inches(18, 10)
[axs[i].plot(residuals.iloc[:,i]) for i in range(4)]
plt.show()
```

Estacionariedad de residuos

```{python}
print('DAX SMI CAC FTSE')
[sts.adfuller(residuals.iloc[:,i])[1] for i in range(4)]
```


Autocorrelacion de los residuos

```{python}
for i in range(4):
  sgt.plot_acf(residuals.iloc[:,i], zero = False, lags = 40)
  plt.show()
  
```

Conclusión: Los residuos del modelo no presentan estructura de autocorrelación, son estacionarios según los resultados de la prueba de Dickey - Fuller aumentada y en los gráficos se puede comprobar esto visualmente, entonces puede concluirse que son ruido blanco como es deseable.

### Valores estimados por el modelo

```{python}
y_fitted = res.fittedvalues
fig, axs = plt.subplots(4)
fig.suptitle('Gráficos de los valores predichos por el modelo',fontsize=20)
fig.set_size_inches(18, 10)
[axs[i].plot(y_fitted.iloc[:,i]) for i in range(4)]
plt.show()
```

## Predicción

Hallar pronosticos de fechas futuras

```{python}
# Obtener el orden del modelo
lag_order = res.k_ar
print('Orden del modelo:', lag_order)
# Input data para hacer forecasting (pronósticos a futuro)
# Se obtinen los ultimos datos dependiendo el orden del modelo
# como es de orden 9, se recuperan los 9 últimos registros de entrenamiento para obtener las predicciones
# del conjunto de prueba
input_data = X_train_transformed.values[-lag_order:]

# Forecasting
pred = res.forecast(y=input_data, steps=n_obs)
pred = (pd.DataFrame(pred, index=X_test.index, columns=X_test.columns + '_pred'))
print('Predicciones:')
pred
```

```{python}
plt.figure(figsize = (12, 10))
res.plot_forecast(lag_order)
plt.tight_layout(h_pad = 1.15)
plt.show()
```

Trasformación de predicciones

```{python}
# Invirtiendo la transformación
def invert_transformation(X_train, pred):
  forecast = pred.copy()
  columns = X_train.columns
  for col in columns:
    forecast[str(col)+'_pred'] = X_train[col].iloc[-1] + forecast[str(col)+'_pred'].cumsum()
  return forecast

output = invert_transformation(X_train, pred)
output
```

### Pronostico de variable DAX

```{python}
plt.figure(figsize = (9,7))
plt.plot(output.iloc[:,0])
plt.title('DAX Forecast')
plt.grid()
plt.show()
```

### Pronostico 30 días adelante

```{python}
pred=res.forecast(X_train_transformed.values, 30)
DAXvalues = pred[:,0]
DAXvalues

DeDiff = np.cumsum(DAXvalues) + X_train.iloc[-1,0]

plt.figure(figsize = (9,7))
plt.plot(DeDiff)
plt.title('Dax Forecast')
plt.grid()
plt.show()
```

Obtener el orden nuevamente

```{python}
# Obtener el orden del modelo
lag_order = 30
print('Orden del modelo:', lag_order)
# Input data para hacer forecasting (pronósticos a futuro)
input_data = X_train_transformed.values[-lag_order:]
# Forecasting
pred = res.forecast(y=input_data, steps=n_obs)
pred = (pd.DataFrame(pred, index=X_test.index, columns=X_test.columns + '_pred'))
print('Predicciones:')
pred

def invert_transformation(X_train, pred):
  forecast = pred.copy()
  columns = X_train.columns
  for col in columns:
    forecast[str(col)+'_pred'] = X_train[col].iloc[-1] + forecast[str(col)+'_pred'].cumsum()
  return forecast

output = invert_transformation(X_train, pred)
output
```

Combinar pronostico con los datos reales

```{python}

# Combinar X_train (datos reales pasados) con las predicciones nuevas
output.columns=['DAX','SMI','CAC','FTSE']
output=output.reset_index(drop=True)
X_train=X_train.reset_index(drop=True)
combineall = pd.concat([X_train, output], axis=0)
combineall=combineall.reset_index(drop=True)
combineall
```

```{python}
plt.figure(figsize = (9,7))
plt.plot(combineall.iloc[1000:1810,0])
plt.plot(combineall.iloc[1809:1860,0],color='red')
plt.title('DAX Forecast')
plt.grid()
plt.show()
```

```{python}

plt.figure(figsize = (9,7))
plt.plot(combineall.iloc[1600:1810,0])
plt.plot(combineall.iloc[1809:1860,0],color='red')
plt.title('DAX Forecast')
plt.grid()
plt.show()
```

